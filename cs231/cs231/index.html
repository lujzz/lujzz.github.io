<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="cs231n学习记录。">
<meta property="og:type" content="article">
<meta property="og:title" content="cs231">
<meta property="og:url" content="https://lllzzz.ltd/cs231/cs231/index.html">
<meta property="og:site_name" content="lujzz_website">
<meta property="og:description" content="cs231n学习记录。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_1(I_1,I_2)=%5Csum_p%7CI%5Ep_1-I%5Ep_2%7C">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_2(I_1,I_2)=%5Csqrt%7B+%5Csum_p(I%5Ep_1-I%5Ep_2)%5E2%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i=%5Csum_%7Bj%5Cnot=y_i%7Dmax(0,s_j-s_%7By_i%7D+%5CDelta)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i=%5Csum_%7Bj%5Cnot=y_i%7Dmax(0,w%5ET_jx_i-w%5ET_%7By_i%7Dx_i+%5CDelta)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=R(W)=%5Csum_k+%5Csum_l+W%5E2_%7Bk,l%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=L=%5Cdisplaystyle+%5Cunderbrace%7B+%5Cfrac%7B1%7D%7BN%7D%5Csum_i+L_i%7D_%7Bdata+%5C++loss%7D+%5Cunderbrace%7B%5Clambda+R(W)%7D_%7Bregularization+%5C+loss%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=L=%5Cfrac%7B1%7D%7BN%7D%5Csum_i%5Csum_%7Bj%5Cnot=y_i%7D%5Bmax(0,f(x_i;W)_j-f(x_i;W)_%7By_i%7D+%5CDelta)%5D+%5Clambda+%5Csum_k+%5Csum_l+W%5E2_%7Bk,l%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+Li=-log(%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cdisplaystyle%5Csigma(x)=1/(1+e%5E%7B-x%7D)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=f(x)=max(0,x)">
<meta property="article:published_time" content="2021-04-08T01:46:20.000Z">
<meta property="article:modified_time" content="2021-04-14T23:59:07.875Z">
<meta property="article:author" content="lujzz">
<meta property="article:tag" content="cs231">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_1(I_1,I_2)=%5Csum_p%7CI%5Ep_1-I%5Ep_2%7C"><title>cs231 | lujzz_website</title><link ref="canonical" href="https://lllzzz.ltd/cs231/cs231/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">lujzz_website</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">cs231</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-04-08</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-04-15</span></span><span class="post-meta-item post-meta-item--wordcount"><span class="post-meta-item__icon"><i class="far fa-file-word"></i></span><span class="post-meta-item__info">字数统计</span><span class="post-meta-item__value">1.1k</span></span><span class="post-meta-item post-meta-item--readtime"><span class="post-meta-item__icon"><i class="far fa-clock"></i></span><span class="post-meta-item__info">阅读时长</span><span class="post-meta-item__value">6分</span></span></div></header><div class="post-body"><p>cs231n学习记录。</p>
 <span id="more"></span> 


        <h2 id="cs231n学习记录"   >
          <a href="#cs231n学习记录" class="heading-link"><i class="fas fa-link"></i></a><a href="#cs231n学习记录" class="headerlink" title="cs231n学习记录"></a>cs231n学习记录</h2>
      
        <h4 id="图像分类"   >
          <a href="#图像分类" class="heading-link"><i class="fas fa-link"></i></a><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h4>
      <ul>
<li><p>图像—（语义差别）—矩阵——特征提取——分类结果</p>
<p>挑战：视角变化、照明条件、形状改变、遮挡情况、图片背景混乱、类内差异——鲁棒性</p>
</li>
<li><p><strong>数据驱动方法</strong>——数据集(<code>dataset</code>)——机器学习训练分类器(<code>Machine Learning-classifier</code>)——评价(<code>evaluate</code>)</p>
<p><code>train-predict</code> </p>
<p><code>cifar-10</code>——<code>Nearest Neighbor分类器</code>——根据相似度进行分类</p>
</li>
<li><p><code>L1 loss:</code></p>
<p><img   src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_1(I_1,I_2)=%5Csum_p%7CI%5Ep_1-I%5Ep_2%7C" style="" ></p>
<p>——求差值然后相加</p>
<p><code>L2 loss:</code> </p>
<p><img   src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_2(I_1,I_2)=%5Csqrt%7B+%5Csum_p(I%5Ep_1-I%5Ep_2)%5E2%7D" style="" ></p>
<p>——欧式距离</p>
</li>
<li><p><code>k-Nearest Neighbor分类器</code></p>
<p>——超参数</p>
</li>
<li><p><strong>数据划分</strong>：</p>
<p><code>train——validation——test</code> （训练集——验证集——测试集）</p>
<p>交叉验证：轮换选择验证集——训练集数据量较小</p>
</li>
<li><p>线性分类器：</p>
<p><code>f(x,W) = W*x + b</code></p>
<p>一个类别对于一个学习模板（矩阵）——权重</p>
</li>
</ul>
<blockquote>
<p>个人理解：原先的邻近分类器可以认为是测试集对于训练集的直达；而进入线性分类器这一节后，可以认为在测试集和训练集之间增加了一个桥梁，通过训练桥梁，提升测试时的性能。并且这种方式更加具有普适性，可以看作是从训练集中得到一种特征提取的方式（这个方式就是现在我们在设计的神经网络，其实的参数确定就来自于训练集），然后再去用已经得到的特征提取的方式预测数据。（不过此处只到线性分类器hhh，神经网络还没有提及到····）</p>
</blockquote>
<p>​    图像——高维空间内的点——空间分割</p>
<p>——局限性</p>

        <h4 id="损失函数"   >
          <a href="#损失函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4>
      <ul>
<li><p>定量判断当前预测方式好坏</p>
</li>
<li><p><code>SVM</code>（支持向量机）</p>
<p><img   src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i=%5Csum_%7Bj%5Cnot=y_i%7Dmax(0,s_j-s_%7By_i%7D+%5CDelta)" style=""  alt="函数定义"></p>
<p>$$<br>s_j:各个分类的得分 \qquad y_i:正确类别号 \qquad \Delta:参数<br>$$</p>
<p>线性评分函数，损失函数改写为：</p>
<p><img   src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i=%5Csum_%7Bj%5Cnot=y_i%7Dmax(0,w%5ET_jx_i-w%5ET_%7By_i%7Dx_i+%5CDelta)" style="" ></p>
<p>目标追求：正确类别的得分比不正确类别的得分高出delta</p>
<p>实际计算：满足目标，不计算损失</p>
<p>​                    不满足目标，计算当前与目标的差值</p>
<p>问题出现：多个权重矩阵W都可以达到<code>loss=0</code>的结果，如何从中寻找我们最想要的W？</p>
<p>问题解决：增加惩罚项——提升泛化性能，避免过拟合——对权重矩阵进行选择</p>
<p>​    例：L2范式</p>
<p>​            <img   src="https://www.zhihu.com/equation?tex=R(W)=%5Csum_k+%5Csum_l+W%5E2_%7Bk,l%7D" style="" ></p>
<p>完整公式：</p>
<p>​            <img   src="https://www.zhihu.com/equation?tex=L=%5Cdisplaystyle+%5Cunderbrace%7B+%5Cfrac%7B1%7D%7BN%7D%5Csum_i+L_i%7D_%7Bdata+%5C++loss%7D+%5Cunderbrace%7B%5Clambda+R(W)%7D_%7Bregularization+%5C+loss%7D" style="" ></p>
<p>​            <img   src="https://www.zhihu.com/equation?tex=L=%5Cfrac%7B1%7D%7BN%7D%5Csum_i%5Csum_%7Bj%5Cnot=y_i%7D%5Bmax(0,f(x_i;W)_j-f(x_i;W)_%7By_i%7D+%5CDelta)%5D+%5Clambda+%5Csum_k+%5Csum_l+W%5E2_%7Bk,l%7D" style="" ></p>
<p>超参数lambda确定</p>
</li>
<li><p><code>softmax</code> ——对得分进行处理，得到各个分类对应的概率——归一化处理</p>
<p>​            <img   src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+Li=-log(%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D)" style="" ></p>
<p>——交叉熵损失</p>
</li>
</ul>

        <h4 id="最优化处理-Optimization"   >
          <a href="#最优化处理-Optimization" class="heading-link"><i class="fas fa-link"></i></a><a href="#最优化处理-Optimization" class="headerlink" title="最优化处理(Optimization)"></a>最优化处理(Optimization)</h4>
      <ul>
<li><p>寻找能使得损失函数值最小化的参数<code>W</code>的过程</p>
</li>
<li><p>随机尝试权重</p>
</li>
<li><p>随机本地搜索——差分法</p>
<p>增加很小的步长来计算梯度</p>
</li>
<li><p>求导得到梯度——<strong>学习率</strong>的设置</p>
<p>——<code>SGD</code>     随机梯度下降法   根据<code>mini-batch</code> 计算梯度</p>
<p>​       鞍点，噪声       <code>SGD+Momentum</code>     <code>Nesterov</code>     <code>Adam</code> </p>
</li>
</ul>

        <h4 id="神经网络介绍"   >
          <a href="#神经网络介绍" class="heading-link"><i class="fas fa-link"></i></a><a href="#神经网络介绍" class="headerlink" title="神经网络介绍"></a>神经网络介绍</h4>
      <ul>
<li><p>反向传播——链式法则计算梯度</p>
</li>
<li><p>上游的梯度与当前本地梯度相乘</p>
</li>
<li><p>max—将梯度传给某一个输入</p>
</li>
<li><p>激活函数——</p>
<ul>
<li><code>sigmoid </code>          <img   src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle%5Csigma(x)=1/(1+e%5E%7B-x%7D)" style="" >——饱和梯度消失</li>
<li><code>ReLU</code>         <img   src="https://www.zhihu.com/equation?tex=f(x)=max(0,x)" style="" ></li>
<li>····</li>
</ul>
</li>
</ul>

        <h4 id="卷积神经网络"   >
          <a href="#卷积神经网络" class="heading-link"><i class="fas fa-link"></i></a><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h4>
      <ul>
<li><p>全连接层：</p>
</li>
<li><p>卷积：</p>
<p><code>(N-F+2*pad)/stride+1</code> </p>
</li>
<li><p>池化层：下采样</p>
</li>
<li><p>激活函数：<code>sigmoid</code>  <code>tanh</code>  <code>ReLU</code>  <code>Leakly ReLU</code>  </p>
</li>
<li><p>数据预处理：零均值化，训练集获得均值</p>
</li>
<li><p>权重初始化：</p>
</li>
<li><p><code>batch normalization</code>  </p>
</li>
<li><p>超参数优化：训练集 验证集</p>
</li>
<li><p>正则化：<code>dropout</code> ：部分神经元置零——减轻过拟合</p>
<p>​               <code>data augmentation</code> 数据增强</p>
<p>——随机性</p>
</li>
<li><p>迁移学习：<code>pretrain</code>  <code>fine-tuning</code> </p>
</li>
</ul>

        <h4 id="深度学习软件"   >
          <a href="#深度学习软件" class="heading-link"><i class="fas fa-link"></i></a><a href="#深度学习软件" class="headerlink" title="深度学习软件"></a>深度学习软件</h4>
      <p><code>pytorch</code>  </p>

        <h4 id="CNN框架"   >
          <a href="#CNN框架" class="heading-link"><i class="fas fa-link"></i></a><a href="#CNN框架" class="headerlink" title="CNN框架"></a>CNN框架</h4>
      <p><code>bottleneck</code>  — 降低计算量</p>
<p><code>resnet</code>  </p>
<p>上采样：</p>

        <h4 id="杂项"   >
          <a href="#杂项" class="heading-link"><i class="fas fa-link"></i></a><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h4>
      
        <h5 id="faster-rcnn"   >
          <a href="#faster-rcnn" class="heading-link"><i class="fas fa-link"></i></a><a href="#faster-rcnn" class="headerlink" title="faster rcnn:"></a><code>faster rcnn:</code></h5>
      <ol>
<li><p>流程：</p>
<p>​    <code>image</code> —–(cnn)—-<code>feature map</code> </p>
<p>​    <code>RPN</code> —–<code>region proposals</code>  :  <code>anchor</code> </p>
<p>​    —-<code>proposal feature maps</code> </p>
</li>
</ol>

        <h5 id="batch-normalization"   >
          <a href="#batch-normalization" class="heading-link"><i class="fas fa-link"></i></a><a href="#batch-normalization" class="headerlink" title="batch normalization:"></a><code>batch normalization:</code></h5>
      <p>批归一化</p>
<p>目的：目的就是使我们的feature map满足均值为0，方差为1的分布规律</p>
<p>训练时要将traning参数设置为True，在验证时将trainning参数设置为False。在pytorch中可通过创建模型的model.train()和model.eval()方法控制</p>
<p>建议将bn层放在卷积层（Conv）和激活层（例如Relu）之间，且卷积层不要使用偏置bias</p>

        <h5 id="权重初始化"   >
          <a href="#权重初始化" class="heading-link"><i class="fas fa-link"></i></a><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h5>
      <p>梯度消失、梯度爆炸</p>
<p>几种可行的初始化方法：</p>
<ul>
<li><p>pretrain 预训练</p>
</li>
<li><p>Xavier 初始化</p>
<p>Xavier初始化的基本思想是，若对于一层网络的 <strong>输出和输出可以保持正态分布且方差相近</strong>，这样就可以避免输出趋向于0，从而避免梯度消失情况。</p>
</li>
<li><p>He初始化</p>
</li>
<li><p>batch normalization+随机初始化</p>
</li>
</ul>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://lllzzz.ltd">lujzz</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://lllzzz.ltd/cs231/cs231/">https://lllzzz.ltd/cs231/cs231/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://lllzzz.ltd/tags/cs231/">cs231</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/%E6%9D%82%E9%A1%B9/matplotlib/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">matplotlib画图记录</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/pytorch/0406/"><span class="paginator-prev__text">损失函数记录</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#cs231n%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95"><span class="toc-number">1.</span> <span class="toc-text">
          cs231n学习记录</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-number">1.0.1.</span> <span class="toc-text">
          图像分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.0.2.</span> <span class="toc-text">
          损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E4%BC%98%E5%8C%96%E5%A4%84%E7%90%86-Optimization"><span class="toc-number">1.0.3.</span> <span class="toc-text">
          最优化处理(Optimization)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.0.4.</span> <span class="toc-text">
          神经网络介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.0.5.</span> <span class="toc-text">
          卷积神经网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%AF%E4%BB%B6"><span class="toc-number">1.0.6.</span> <span class="toc-text">
          深度学习软件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CNN%E6%A1%86%E6%9E%B6"><span class="toc-number">1.0.7.</span> <span class="toc-text">
          CNN框架</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%82%E9%A1%B9"><span class="toc-number">1.0.8.</span> <span class="toc-text">
          杂项</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#faster-rcnn"><span class="toc-number">1.0.8.1.</span> <span class="toc-text">
          faster rcnn:</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#batch-normalization"><span class="toc-number">1.0.8.2.</span> <span class="toc-text">
          batch normalization:</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">1.0.8.3.</span> <span class="toc-text">
          权重初始化</span></a></li></ol></li></ol></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/riki_2.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">lujzz</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">17</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">11</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">16</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>lujzz</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v5.4.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>